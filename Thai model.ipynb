{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ffe5360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: 21850\n",
      "Emotions\n",
      "frustrated    6161\n",
      "neutral       5863\n",
      "happy         3047\n",
      "angry         2475\n",
      "sad           2230\n",
      "none          2072\n",
      "other            2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s001_con_actor001_impro1_1.flac</td>\n",
       "      <td>neutral</td>\n",
       "      <td>C:\\Users\\Phattarapol\\Desktop\\Senior Project\\Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s001_con_actor001_impro1_10.flac</td>\n",
       "      <td>neutral</td>\n",
       "      <td>C:\\Users\\Phattarapol\\Desktop\\Senior Project\\Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s001_con_actor001_impro1_11.flac</td>\n",
       "      <td>neutral</td>\n",
       "      <td>C:\\Users\\Phattarapol\\Desktop\\Senior Project\\Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s001_con_actor001_impro1_12.flac</td>\n",
       "      <td>neutral</td>\n",
       "      <td>C:\\Users\\Phattarapol\\Desktop\\Senior Project\\Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s001_con_actor001_impro1_13.flac</td>\n",
       "      <td>neutral</td>\n",
       "      <td>C:\\Users\\Phattarapol\\Desktop\\Senior Project\\Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               File Emotions  \\\n",
       "0   s001_con_actor001_impro1_1.flac  neutral   \n",
       "1  s001_con_actor001_impro1_10.flac  neutral   \n",
       "2  s001_con_actor001_impro1_11.flac  neutral   \n",
       "3  s001_con_actor001_impro1_12.flac  neutral   \n",
       "4  s001_con_actor001_impro1_13.flac  neutral   \n",
       "\n",
       "                                                Path  \n",
       "0  C:\\Users\\Phattarapol\\Desktop\\Senior Project\\Th...  \n",
       "1  C:\\Users\\Phattarapol\\Desktop\\Senior Project\\Th...  \n",
       "2  C:\\Users\\Phattarapol\\Desktop\\Senior Project\\Th...  \n",
       "3  C:\\Users\\Phattarapol\\Desktop\\Senior Project\\Th...  \n",
       "4  C:\\Users\\Phattarapol\\Desktop\\Senior Project\\Th...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# üìÅ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á Thai Dataset\n",
    "DATA_DIR = \"C:\\\\Users\\\\Phattarapol\\\\Desktop\\\\Senior Project\\\\Thai Dataset\"\n",
    "\n",
    "# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå emotion label\n",
    "with open(\"emotion_label.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    emo_data = json.load(f)\n",
    "\n",
    "# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏´‡∏≤ path ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
    "def find_file_path(filename):\n",
    "    for studio_id in range(1, 81):  # ‚úÖ ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ studio001 ‡∏ñ‡∏∂‡∏á studio080\n",
    "        studio_folder = f\"studio{studio_id:03d}\"\n",
    "        file_path = os.path.join(DATA_DIR, studio_folder, \"con\", filename)\n",
    "        if os.path.exists(file_path):\n",
    "            return file_path\n",
    "    return None  # ‚ùå ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠\n",
    "\n",
    "# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠\n",
    "records = []\n",
    "\n",
    "for filename, label in emo_data.items():\n",
    "    info = label[0]\n",
    "    majority_emo = info[\"majority_emo\"].lower()\n",
    "    path = find_file_path(filename)\n",
    "    if path is not None:\n",
    "        records.append({\n",
    "            \"File\": filename,\n",
    "            \"Emotions\": majority_emo,\n",
    "            \"Path\": path\n",
    "        })\n",
    "\n",
    "# ‚úÖ ‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# ‚úÖ ‡∏î‡∏π‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö\n",
    "print(f\"‚úÖ ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df)}\")\n",
    "print(df[\"Emotions\"].value_counts())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a1c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_emotions = ['neutral', 'happy', 'sad', 'angry']\n",
    "df = df[df['Emotions'].isin(target_emotions)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eaa3c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions\n",
      "neutral    5863\n",
      "happy      3047\n",
      "angry      2475\n",
      "sad        2230\n",
      "Name: count, dtype: int64\n",
      "['neutral' 'angry' 'happy' 'sad']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Emotions\"].value_counts())\n",
    "print(df[\"Emotions\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b11e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 1: Library\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import WhisperProcessor, WhisperModel, WhisperForConditionalGeneration\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import resample\n",
    "import random\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "AUGMENTED_DIR = \"C:\\\\Users\\\\Phattarapol\\\\Desktop\\\\Senior Project\\\\Thai Dataset\\\\DataAugment\"\n",
    "os.makedirs(AUGMENTED_DIR, exist_ok=True)\n",
    "\n",
    "def augment_and_save(waveform, sr, idx, method=\"noise\"):\n",
    "    if method == \"noise\":\n",
    "        noise = 0.005 * torch.randn_like(waveform)\n",
    "        augmented = waveform + noise\n",
    "    elif method == \"pitch\":\n",
    "        augmented = T.Resample(sr, sr)(waveform)\n",
    "        augmented = T.PitchShift(sr, n_steps=2)(augmented)\n",
    "    elif method == \"speed\":\n",
    "        speed_factor = random.uniform(0.9, 1.1)\n",
    "        augmented = T.Resample(sr, int(sr * speed_factor))(waveform)\n",
    "    else:\n",
    "        augmented = waveform\n",
    "\n",
    "    augmented = augmented.detach()\n",
    "    path = os.path.join(AUGMENTED_DIR, f\"aug_{idx}_{method}.wav\")\n",
    "    torchaudio.save(path, augmented, sr)\n",
    "    return path\n",
    "\n",
    "def balance_dataset_with_real_augmentation(df, target_per_class=5863):\n",
    "    balanced_rows = []\n",
    "    idx_counter = 0\n",
    "\n",
    "    for emotion in df[\"Emotions\"].unique():\n",
    "        df_emotion = df[df[\"Emotions\"] == emotion]\n",
    "        n_samples = len(df_emotion)\n",
    "\n",
    "        # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô\n",
    "        df_emotion_copy = df_emotion.copy()\n",
    "        df_emotion_copy[\"augmented\"] = False\n",
    "        balanced_rows.append(df_emotion_copy)\n",
    "\n",
    "        if n_samples < target_per_class:\n",
    "            n_needed = target_per_class - n_samples\n",
    "            sampled = resample(df_emotion, replace=True, n_samples=n_needed, random_state=42)\n",
    "\n",
    "            augmented_rows = []\n",
    "            for _, row in sampled.iterrows():\n",
    "                waveform, sr = torchaudio.load(row[\"Path\"])\n",
    "                waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
    "                waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "                method = random.choice([\"noise\", \"pitch\", \"speed\"])\n",
    "                aug_path = augment_and_save(waveform, 16000, idx_counter, method)\n",
    "                idx_counter += 1\n",
    "\n",
    "                augmented_rows.append({\n",
    "                    \"Path\": aug_path,\n",
    "                    \"Emotions\": row[\"Emotions\"],\n",
    "                    \"augmented\": True\n",
    "                })\n",
    "\n",
    "            balanced_rows.append(pd.DataFrame(augmented_rows))\n",
    "\n",
    "        elif n_samples > target_per_class:\n",
    "            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÄ‡∏Å‡∏¥‡∏ô ‡∏Å‡πá‡∏ï‡∏±‡∏î‡∏•‡∏á‡∏°‡∏≤\n",
    "            trimmed = resample(df_emotion, replace=False, n_samples=target_per_class, random_state=42)\n",
    "            trimmed[\"augmented\"] = False\n",
    "            balanced_rows.append(trimmed)\n",
    "\n",
    "    balanced_df = pd.concat(balanced_rows).reset_index(drop=True)\n",
    "    return balanced_df\n",
    "\n",
    "# ‚úÖ Step 2: Dataset Class\n",
    "class SERDataset(Dataset):\n",
    "    def __init__(self, dataframe, processor, label_encoder, max_len=30):\n",
    "        self.df = dataframe\n",
    "        self.processor = processor\n",
    "        self.label_encoder = label_encoder\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.iloc[idx]['Path']\n",
    "        label = self.df.iloc[idx]['Emotions']\n",
    "        is_aug = self.df.iloc[idx].get(\"augmented\", False)\n",
    "        \n",
    "        waveform, sr = torchaudio.load(path)\n",
    "        waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
    "\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    \n",
    "        inputs = self.processor(\n",
    "            waveform.squeeze().numpy(),  # shape: [time]\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        input_features = inputs.input_features.squeeze(0)\n",
    "\n",
    "        label_id = self.label_encoder.transform([str(label)])[0]\n",
    "        # print(f\"{idx} => {input_features.shape}\")\n",
    "\n",
    "        return {\n",
    "            \"input_features\": inputs.input_features.squeeze(0),\n",
    "            \"label\": torch.tensor(label_id, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# ‚úÖ Step 3: Model with classifier head\n",
    "class WhisperEmotionClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = WhisperModel.from_pretrained(\"openai/whisper-tiny\").encoder\n",
    "        # self.backbone = WhisperModel.from_pretrained(\"openai/whisper-large-v3\").encoder\n",
    "\n",
    "        hidden_size = self.backbone.config.hidden_size  # üëà ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å config\n",
    "        self.projector = nn.Linear(hidden_size, 256)\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, input_features):\n",
    "        outputs = self.backbone(input_features=input_features)\n",
    "        hidden = outputs.last_hidden_state.mean(dim=1)\n",
    "        x = self.projector(hidden)\n",
    "        x = F.relu(x)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "204e0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode emotions\n",
    "# label_encoder = LabelEncoder()\n",
    "# df[\"Emotions\"] = label_encoder.fit_transform(df[\"Emotions\"])\n",
    "\n",
    "# # ‡∏ó‡∏≥ augmentation ‡πÅ‡∏•‡∏∞ balance dataset ‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
    "# balanced_df = balance_dataset_with_real_augmentation(df, target_per_class=5863)\n",
    "# balanced_df.to_csv(\"balanced_Thai_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4750ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÅ 1. ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏ã‡∏ü‡πÑ‡∏ß‡πâ\n",
    "balanced_df = pd.read_csv(\"balanced_Thai_data.csv\")\n",
    "\n",
    "# üîÅ 2. ‡πÅ‡∏õ‡∏•‡∏á label ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "id2label = {0: 'angry', 1: 'happy', 2: 'neutral', 3: 'sad'}\n",
    "if balanced_df[\"Emotions\"].dtype in [int, float]:\n",
    "    balanced_df[\"Emotions\"] = balanced_df[\"Emotions\"].map(lambda x: id2label[int(x)])\n",
    "\n",
    "# üîÅ 3. Encode Label\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(balanced_df[\"Emotions\"])\n",
    "\n",
    "# üîÅ 4. Split ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(balanced_df, test_size=0.2, stratify=balanced_df[\"Emotions\"])\n",
    "\n",
    "# üîÅ 5. Load processor ‡πÅ‡∏•‡∏∞ dataset\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "train_dataset = SERDataset(train_df, processor, label_encoder)\n",
    "test_dataset = SERDataset(test_df, processor, label_encoder)\n",
    "\n",
    "# üîÅ 6. Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78483db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'angry' 'happy' 'sad']\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Emotions\"].unique())\n",
    "print(df[\"Emotions\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70c7caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions\n",
      "neutral    5863\n",
      "angry      5863\n",
      "happy      5863\n",
      "sad        5863\n",
      "Name: count, dtype: int64\n",
      "['neutral' 'angry' 'happy' 'sad']\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(balanced_df[\"Emotions\"].value_counts())\n",
    "print(balanced_df[\"Emotions\"].unique())\n",
    "print(balanced_df[\"Emotions\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bf06e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'happy' 'neutral' 'sad']\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.classes_)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà fit ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59a2afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_backbone(model):\n",
    "        for param in model.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(\"üîí Backbone frozen.\")\n",
    "\n",
    "def unfreeze_backbone(model):\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = True\n",
    "    print(\"üîì Backbone unfrozen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31365f",
   "metadata": {},
   "source": [
    "# Freeze Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67222478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 5: Training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = WhisperEmotionClassifier(num_classes=len(label_encoder.classes_)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283680bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí Backbone frozen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|‚ñà         | 124/1173 [03:45<31:27,  1.80s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Load pre-trained weights if available\n",
    "model.load_state_dict(torch.load(\"best_model2.pth\"))\n",
    "model.train()\n",
    "\n",
    "freeze_backbone(model)  # üîí Freeze backbone\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "best_acc = 0\n",
    "patience = 3\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(50):\n",
    "    if epoch % 3 == 0:\n",
    "        time.sleep(60)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        inputs = batch['input_features'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    acc = correct / total\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(acc)\n",
    "    print(f\"[Freeze Phase] Epoch {epoch+1}: Loss={total_loss:.4f}, Acc={correct/total:.4f}\")\n",
    "\n",
    "    # ‚úÖ Step 6: Evaluate\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = batch['input_features'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_avg_loss = val_loss / len(test_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    val_losses.append(val_avg_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Val Loss: {val_avg_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), \"best_model_thai.pth\")  # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏ß‡πâ\n",
    "        print(\"‚úÖ New best model saved.\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        print(f\"‚ö†Ô∏è No improvement for {no_improve} epoch(s).\")\n",
    "\n",
    "        if no_improve >= patience:\n",
    "            print(\"üõë Early stopping triggered.\")\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SeniorProject",
   "language": "python",
   "name": "seniorproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
